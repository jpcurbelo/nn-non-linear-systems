{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 14:14:53.329875: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-18 14:14:54.300456: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-18 14:14:56.593094: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-18 14:14:56.593169: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-18 14:14:56.612110: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-18 14:14:57.703762: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-18 14:14:57.707100: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-18 14:15:08.869572: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from sympy import symbols, sympify, lambdify\n",
    "from tabulate import tabulate\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.constraints import NonNeg\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "seed_value = 2023\n",
    "tf.random.set_seed(seed_value)\n",
    "np.random.seed(seed_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e-07"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.backend.epsilon()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_precision = tf.float64\n",
    "np_precision = np.float64\n",
    "\n",
    "with open('config_run.yml', 'r') as ymlfile:\n",
    "    config_data = yaml.load(ymlfile, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_name = config_data['problem_folder']\n",
    "EQS_FILE = problem_name + '.json'\n",
    "EQS_PATH = os.path.join(os.getcwd(), problem_name, EQS_FILE)\n",
    "\n",
    "training_steps = config_data['epochs']\n",
    "display_step = training_steps // 20\n",
    "\n",
    "load_initial_estimate = config_data['load_initial_estimate']\n",
    "save_best_solution = config_data['save_best_solution']\n",
    "\n",
    "if len(list(config_data['learning_rate'].keys())) > 1:\n",
    "    lr_steps = [int(training_steps * key / 100) for key in list(config_data['learning_rate'].keys()) if key != 0]\n",
    "    lr_values = [float(val) for val in list(config_data['learning_rate'].values())]\n",
    "    learning_rate = tf.keras.optimizers.schedules.PiecewiseConstantDecay(lr_steps, lr_values)\n",
    "else:\n",
    "    learning_rate = float(list(config_data['learning_rate'].values())[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [2.0, 2.0, 2.0, 2.0, 2.0], [6.0, 6.0, 6.0, 6.0], [3.0, 3.0, 3.0, 3.0, 3.0], [24.0, 24.0, 24.0], [12.0, 12.0, 12.0, 12.0], [8.0, 8.0, 8.0, 8.0], [4.0, 4.0, 4.0, 4.0, 4.0], [120.0, 120.0], [60.0, 60.0, 60.0], [40.0, 40.0, 40.0], [30.0, 30.0, 30.0], [20.0, 20.0, 20.0, 20.0], [15.0, 15.0, 15.0, 15.0], [20.0, 20.0, 20.0, 20.0], [10.0, 10.0, 10.0, 10.0], [5.0, 5.0, 5.0, 5.0, 5.0]]\n",
      "['b_1', 'b_2', 'b_3', 'b_4', 'b_5', 'b_6', 'a_21*b_2', 'b_3*(a_31 + a_32)', 'b_4*(a_41 + a_42 + a_43)', 'b_5*(a_51 + a_52 + a_53 + a_54)', 'b_6*(a_61 + a_62 + a_63 + a_64 + a_65)', 'b_4*(a_21*a_42 + a_43*(a_31 + a_32))', 'b_5*(a_21*a_52 + a_53*(a_31 + a_32) + a_54*(a_41 + a_42 + a_43))', 'b_6*(a_21*a_62 + a_63*(a_31 + a_32) + a_64*(a_41 + a_42 + a_43) + a_65*(a_51 + a_52 + a_53 + a_54))', 'a_21*a_32*b_3', 'a_21**2*b_2', 'b_3*(a_31 + a_32)**2', 'b_4*(a_41 + a_42 + a_43)**2', 'b_5*(a_51 + a_52 + a_53 + a_54)**2', 'b_6*(a_61 + a_62 + a_63 + a_64 + a_65)**2', 'b_5*(a_21*a_32*a_53 + a_54*(a_21*a_42 + a_43*(a_31 + a_32)))', 'b_6*(a_21*a_32*a_63 + a_64*(a_21*a_42 + a_43*(a_31 + a_32)) + a_65*(a_21*a_52 + a_53*(a_31 + a_32) + a_54*(a_41 + a_42 + a_43)))', 'a_21*a_32*a_43*b_4', 'b_4*(a_21**2*a_42 + a_43*(a_31 + a_32)**2)', 'b_5*(a_21**2*a_52 + a_53*(a_31 + a_32)**2 + a_54*(a_41 + a_42 + a_43)**2)', 'b_6*(a_21**2*a_62 + a_63*(a_31 + a_32)**2 + a_64*(a_41 + a_42 + a_43)**2 + a_65*(a_51 + a_52 + a_53 + a_54)**2)', 'a_21**2*a_32*b_3', 'b_4*(a_21*a_42 + a_43*(a_31 + a_32))*(a_41 + a_42 + a_43)', 'b_5*(a_21*a_52 + a_53*(a_31 + a_32) + a_54*(a_41 + a_42 + a_43))*(a_51 + a_52 + a_53 + a_54)', 'b_6*(a_21*a_62 + a_63*(a_31 + a_32) + a_64*(a_41 + a_42 + a_43) + a_65*(a_51 + a_52 + a_53 + a_54))*(a_61 + a_62 + a_63 + a_64 + a_65)', 'a_21*a_32*b_3*(a_31 + a_32)', 'a_21**3*b_2', 'b_3*(a_31 + a_32)**3', 'b_4*(a_41 + a_42 + a_43)**3', 'b_5*(a_51 + a_52 + a_53 + a_54)**3', 'b_6*(a_61 + a_62 + a_63 + a_64 + a_65)**3', 'b_6*(a_21*a_32*a_43*a_64 + a_65*(a_21*a_32*a_53 + a_54*(a_21*a_42 + a_43*(a_31 + a_32))))', 'a_21*a_32*a_43*a_54*b_5', 'b_5*(a_21**2*a_32*a_53 + a_54*(a_21**2*a_42 + a_43*(a_31 + a_32)**2))', 'b_6*(a_21**2*a_32*a_63 + a_64*(a_21**2*a_42 + a_43*(a_31 + a_32)**2) + a_65*(a_21**2*a_52 + a_53*(a_31 + a_32)**2 + a_54*(a_41 + a_42 + a_43)**2))', 'a_21**2*a_32*a_43*b_4', 'b_5*(a_21*a_32*a_53*(a_31 + a_32) + a_54*(a_21*a_42 + a_43*(a_31 + a_32))*(a_41 + a_42 + a_43))', 'b_6*(a_21*a_32*a_63*(a_31 + a_32) + a_64*(a_21*a_42 + a_43*(a_31 + a_32))*(a_41 + a_42 + a_43) + a_65*(a_21*a_52 + a_53*(a_31 + a_32) + a_54*(a_41 + a_42 + a_43))*(a_51 + a_52 + a_53 + a_54))', 'a_21*a_32*a_43*b_4*(a_31 + a_32)', 'b_5*(a_21*a_32*a_53 + a_54*(a_21*a_42 + a_43*(a_31 + a_32)))*(a_51 + a_52 + a_53 + a_54)', 'b_6*(a_21*a_32*a_63 + a_64*(a_21*a_42 + a_43*(a_31 + a_32)) + a_65*(a_21*a_52 + a_53*(a_31 + a_32) + a_54*(a_41 + a_42 + a_43)))*(a_61 + a_62 + a_63 + a_64 + a_65)', 'a_21*a_32*a_43*b_4*(a_41 + a_42 + a_43)', 'b_4*(a_21**3*a_42 + a_43*(a_31 + a_32)**3)', 'b_5*(a_21**3*a_52 + a_53*(a_31 + a_32)**3 + a_54*(a_41 + a_42 + a_43)**3)', 'b_6*(a_21**3*a_62 + a_63*(a_31 + a_32)**3 + a_64*(a_41 + a_42 + a_43)**3 + a_65*(a_51 + a_52 + a_53 + a_54)**3)', 'a_21**3*a_32*b_3', 'b_4*(a_21**2*a_42 + a_43*(a_31 + a_32)**2)*(a_41 + a_42 + a_43)', 'b_5*(a_21**2*a_52 + a_53*(a_31 + a_32)**2 + a_54*(a_41 + a_42 + a_43)**2)*(a_51 + a_52 + a_53 + a_54)', 'b_6*(a_21**2*a_62 + a_63*(a_31 + a_32)**2 + a_64*(a_41 + a_42 + a_43)**2 + a_65*(a_51 + a_52 + a_53 + a_54)**2)*(a_61 + a_62 + a_63 + a_64 + a_65)', 'a_21**2*a_32*b_3*(a_31 + a_32)', 'b_4*(a_21*a_42 + a_43*(a_31 + a_32))**2', 'b_5*(a_21*a_52 + a_53*(a_31 + a_32) + a_54*(a_41 + a_42 + a_43))**2', 'b_6*(a_21*a_62 + a_63*(a_31 + a_32) + a_64*(a_41 + a_42 + a_43) + a_65*(a_51 + a_52 + a_53 + a_54))**2', 'a_21**2*a_32**2*b_3', 'b_4*(a_21*a_42 + a_43*(a_31 + a_32))*(a_41 + a_42 + a_43)**2', 'b_5*(a_21*a_52 + a_53*(a_31 + a_32) + a_54*(a_41 + a_42 + a_43))*(a_51 + a_52 + a_53 + a_54)**2', 'b_6*(a_21*a_62 + a_63*(a_31 + a_32) + a_64*(a_41 + a_42 + a_43) + a_65*(a_51 + a_52 + a_53 + a_54))*(a_61 + a_62 + a_63 + a_64 + a_65)**2', 'a_21*a_32*b_3*(a_31 + a_32)**2', 'a_21**4*b_2', 'b_3*(a_31 + a_32)**4', 'b_4*(a_41 + a_42 + a_43)**4', 'b_5*(a_51 + a_52 + a_53 + a_54)**4', 'b_6*(a_61 + a_62 + a_63 + a_64 + a_65)**4']\n",
      "[b_1, b_2, b_3, b_4, b_5, b_6, a_21*b_2, b_3*(a_31 + a_32), b_4*(a_41 + a_42 + a_43), b_5*(a_51 + a_52 + a_53 + a_54), b_6*(a_61 + a_62 + a_63 + a_64 + a_65), b_4*(a_21*a_42 + a_43*(a_31 + a_32)), b_5*(a_21*a_52 + a_53*(a_31 + a_32) + a_54*(a_41 + a_42 + a_43)), b_6*(a_21*a_62 + a_63*(a_31 + a_32) + a_64*(a_41 + a_42 + a_43) + a_65*(a_51 + a_52 + a_53 + a_54)), a_21*a_32*b_3, a_21**2*b_2, b_3*(a_31 + a_32)**2, b_4*(a_41 + a_42 + a_43)**2, b_5*(a_51 + a_52 + a_53 + a_54)**2, b_6*(a_61 + a_62 + a_63 + a_64 + a_65)**2, b_5*(a_21*a_32*a_53 + a_54*(a_21*a_42 + a_43*(a_31 + a_32))), b_6*(a_21*a_32*a_63 + a_64*(a_21*a_42 + a_43*(a_31 + a_32)) + a_65*(a_21*a_52 + a_53*(a_31 + a_32) + a_54*(a_41 + a_42 + a_43))), a_21*a_32*a_43*b_4, b_4*(a_21**2*a_42 + a_43*(a_31 + a_32)**2), b_5*(a_21**2*a_52 + a_53*(a_31 + a_32)**2 + a_54*(a_41 + a_42 + a_43)**2), b_6*(a_21**2*a_62 + a_63*(a_31 + a_32)**2 + a_64*(a_41 + a_42 + a_43)**2 + a_65*(a_51 + a_52 + a_53 + a_54)**2), a_21**2*a_32*b_3, b_4*(a_21*a_42 + a_43*(a_31 + a_32))*(a_41 + a_42 + a_43), b_5*(a_21*a_52 + a_53*(a_31 + a_32) + a_54*(a_41 + a_42 + a_43))*(a_51 + a_52 + a_53 + a_54), b_6*(a_21*a_62 + a_63*(a_31 + a_32) + a_64*(a_41 + a_42 + a_43) + a_65*(a_51 + a_52 + a_53 + a_54))*(a_61 + a_62 + a_63 + a_64 + a_65), a_21*a_32*b_3*(a_31 + a_32), a_21**3*b_2, b_3*(a_31 + a_32)**3, b_4*(a_41 + a_42 + a_43)**3, b_5*(a_51 + a_52 + a_53 + a_54)**3, b_6*(a_61 + a_62 + a_63 + a_64 + a_65)**3, b_6*(a_21*a_32*a_43*a_64 + a_65*(a_21*a_32*a_53 + a_54*(a_21*a_42 + a_43*(a_31 + a_32)))), a_21*a_32*a_43*a_54*b_5, b_5*(a_21**2*a_32*a_53 + a_54*(a_21**2*a_42 + a_43*(a_31 + a_32)**2)), b_6*(a_21**2*a_32*a_63 + a_64*(a_21**2*a_42 + a_43*(a_31 + a_32)**2) + a_65*(a_21**2*a_52 + a_53*(a_31 + a_32)**2 + a_54*(a_41 + a_42 + a_43)**2)), a_21**2*a_32*a_43*b_4, b_5*(a_21*a_32*a_53*(a_31 + a_32) + a_54*(a_21*a_42 + a_43*(a_31 + a_32))*(a_41 + a_42 + a_43)), b_6*(a_21*a_32*a_63*(a_31 + a_32) + a_64*(a_21*a_42 + a_43*(a_31 + a_32))*(a_41 + a_42 + a_43) + a_65*(a_21*a_52 + a_53*(a_31 + a_32) + a_54*(a_41 + a_42 + a_43))*(a_51 + a_52 + a_53 + a_54)), a_21*a_32*a_43*b_4*(a_31 + a_32), b_5*(a_21*a_32*a_53 + a_54*(a_21*a_42 + a_43*(a_31 + a_32)))*(a_51 + a_52 + a_53 + a_54), b_6*(a_21*a_32*a_63 + a_64*(a_21*a_42 + a_43*(a_31 + a_32)) + a_65*(a_21*a_52 + a_53*(a_31 + a_32) + a_54*(a_41 + a_42 + a_43)))*(a_61 + a_62 + a_63 + a_64 + a_65), a_21*a_32*a_43*b_4*(a_41 + a_42 + a_43), b_4*(a_21**3*a_42 + a_43*(a_31 + a_32)**3), b_5*(a_21**3*a_52 + a_53*(a_31 + a_32)**3 + a_54*(a_41 + a_42 + a_43)**3), b_6*(a_21**3*a_62 + a_63*(a_31 + a_32)**3 + a_64*(a_41 + a_42 + a_43)**3 + a_65*(a_51 + a_52 + a_53 + a_54)**3), a_21**3*a_32*b_3, b_4*(a_21**2*a_42 + a_43*(a_31 + a_32)**2)*(a_41 + a_42 + a_43), b_5*(a_21**2*a_52 + a_53*(a_31 + a_32)**2 + a_54*(a_41 + a_42 + a_43)**2)*(a_51 + a_52 + a_53 + a_54), b_6*(a_21**2*a_62 + a_63*(a_31 + a_32)**2 + a_64*(a_41 + a_42 + a_43)**2 + a_65*(a_51 + a_52 + a_53 + a_54)**2)*(a_61 + a_62 + a_63 + a_64 + a_65), a_21**2*a_32*b_3*(a_31 + a_32), b_4*(a_21*a_42 + a_43*(a_31 + a_32))**2, b_5*(a_21*a_52 + a_53*(a_31 + a_32) + a_54*(a_41 + a_42 + a_43))**2, b_6*(a_21*a_62 + a_63*(a_31 + a_32) + a_64*(a_41 + a_42 + a_43) + a_65*(a_51 + a_52 + a_53 + a_54))**2, a_21**2*a_32**2*b_3, b_4*(a_21*a_42 + a_43*(a_31 + a_32))*(a_41 + a_42 + a_43)**2, b_5*(a_21*a_52 + a_53*(a_31 + a_32) + a_54*(a_41 + a_42 + a_43))*(a_51 + a_52 + a_53 + a_54)**2, b_6*(a_21*a_62 + a_63*(a_31 + a_32) + a_64*(a_41 + a_42 + a_43) + a_65*(a_51 + a_52 + a_53 + a_54))*(a_61 + a_62 + a_63 + a_64 + a_65)**2, a_21*a_32*b_3*(a_31 + a_32)**2, a_21**4*b_2, b_3*(a_31 + a_32)**4, b_4*(a_41 + a_42 + a_43)**4, b_5*(a_51 + a_52 + a_53 + a_54)**4, b_6*(a_61 + a_62 + a_63 + a_64 + a_65)**4]\n"
     ]
    }
   ],
   "source": [
    "# Read the JSON data from the file\n",
    "with open(EQS_PATH, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "variables = data['variables']\n",
    "equations = data['equations']\n",
    "# equation_terms = data['equation_terms']\n",
    "\n",
    "variables_str = ' '.join(variables)\n",
    "variables_sym = symbols(variables_str)\n",
    "equations_sym = [sympify(eq) for eq in equations]  \n",
    "\n",
    "## Identify the equation terms\n",
    "equation_terms = []\n",
    "for (i, eq) in enumerate(equations_sym):\n",
    "    terms = []\n",
    "    if eq in variables_sym:\n",
    "        terms.append(str(eq))\n",
    "    else:\n",
    "        for term in eq.args:\n",
    "            terms.append(str(term))\n",
    "    equation_terms.append(terms)\n",
    "\n",
    "# Initialize a list to store the coefficients\n",
    "scalar_coefficients = []\n",
    "functions = []\n",
    "bias_coefficients = []\n",
    "\n",
    "# Loop through the equation terms\n",
    "for terms in equation_terms:\n",
    "    if terms[0] in variables:\n",
    "        bias_coefficients.append(0.0)\n",
    "    else:\n",
    "        bias_coefficients.append(float(terms[0]))\n",
    "    coefficients = []   \n",
    "    if len(terms) == 1 and terms[0] in variables:\n",
    "        scalar_coefficients.append([1.0])\n",
    "        functions.append(terms[0])\n",
    "        continue\n",
    "    for term in terms[1:]:\n",
    "        # Split each term by the first '*'\n",
    "        term_parts = term.split('*')\n",
    "        # Extract the scalar coefficient or default to '1'\n",
    "        scalar_coeff = term_parts[0] if len(term_parts) > 1 and term_parts[0] not in variables else '1.0'\n",
    "        coefficients.append(float(scalar_coeff))\n",
    "               \n",
    "        # Remove first occurrence of scalar coefficient from the term\n",
    "        func_coeff = term.replace(term_parts[0]+'*', '', 1) if len(term_parts) > 1 and term_parts[0] not in variables else term\n",
    "        # print(func_coeff)\n",
    "        functions.append(func_coeff)\n",
    "        \n",
    "    scalar_coefficients.append(coefficients)   \n",
    "       \n",
    "functions_sym = [sympify(func) for func in functions]       \n",
    "        \n",
    "print(bias_coefficients)\n",
    "print(scalar_coefficients)\n",
    "print(functions)\n",
    "print(functions_sym)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_most_recent_estimate(problem_name, prefix=\"best_estimate\"):\n",
    "    # Find all JSON files with the specified prefix\n",
    "    pattern = os.path.join(problem_name, f\"{prefix}_*.json\")\n",
    "    files = glob.glob(pattern)\n",
    "\n",
    "    if not files:\n",
    "        print(f\"No files found with prefix '{prefix}'\")\n",
    "        return None\n",
    "\n",
    "    # Get the most recent file based on modification time\n",
    "    most_recent_file = max(files, key=os.path.getmtime)\n",
    "    \n",
    "    print(f\"Loading most recent estimate from {most_recent_file}\")\n",
    "\n",
    "    # Load json file with initial estimate (best from the most recent run)\n",
    "    with open(most_recent_file, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    return data['best_solution']\n",
    "\n",
    "\n",
    "def evaluate_tf_function(inputs, values, symbolic_function):\n",
    "    # Ensure that the number of inputs and values match\n",
    "    if len(inputs) != len(values):\n",
    "        raise ValueError(\"Number of inputs and values must match.\")\n",
    "\n",
    "    # Evaluate the symbolic function using TensorFlow and the provided values\n",
    "    result = symbolic_function(*values)\n",
    "    # Convert the result to a TensorFlow tensor\n",
    "    result = tf.convert_to_tensor(result, dtype=tf_precision)\n",
    "    \n",
    "    # print(result.__class__)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Define the custom activation function with @tf.function\n",
    "# @tf.function\n",
    "def activation_layer2(layer, vars=variables_sym, funcs=functions_sym):\n",
    "    \n",
    "    layer_values = layer.numpy()[0]\n",
    "    var_vals = [tf.squeeze(layer[0, i]) for i in range(layer_values.shape[0])]\n",
    "       \n",
    "    layer_act = list()\n",
    "    for func in funcs:\n",
    "        func_tf = lambdify(vars, func, 'tensorflow')\n",
    "        layer_act.append(evaluate_tf_function(variables_sym, var_vals, func_tf))\n",
    "    \n",
    "    # Convert layer_act to a TensorFlow tensor\n",
    "    layer_2 = tf.convert_to_tensor(layer_act, dtype=tf_precision)\n",
    "    layer_2 = tf.reshape(layer_2, [1, len(funcs)])\n",
    "\n",
    "    return layer_2\n",
    "\n",
    "\n",
    "# Create model\n",
    "def multilayer_perceptron(weights, biases):\n",
    "\n",
    "    # # Reshape input if necessary, matching the shape of the first layer's weights\n",
    "    # x = tf.reshape(x, [1, -1])  # Adjust the shape as needed\n",
    "\n",
    "    # layer_1 = tf.add(tf.matmul(x, weights['w12']), biases['b12'])\n",
    "    # layer_1 = tf.matmul(x, weights['w12'])\n",
    "    layer_1 = weights['w12']\n",
    "    \n",
    "    # print(f'layer_1 = {layer_1.shape}')\n",
    "\n",
    "    layer_2 = activation_layer2(layer_1)\n",
    "    \n",
    "    # Output fully connected layer\n",
    "    output = tf.add(tf.matmul(layer_2, weights['w34']), biases['out'])\n",
    "    \n",
    "    # # Add RELU activation function to output layer\n",
    "    # output = tf.nn.relu(output)\n",
    "    \n",
    "    return output, layer_1\n",
    "\n",
    "\n",
    "def loss_function(weights, biases, lambda_reg=0.01):\n",
    "    \n",
    "    output, _ = multilayer_perceptron(weights, biases)\n",
    "    \n",
    "    # # L2 regularization term for weights\n",
    "    # regularization_term = sum(tf.nn.l2_loss(w) for w in weights.values())\n",
    "    \n",
    "    # L1 regularization term for weights - to enforce sparsity\n",
    "    # L1 regularization adds the sum of the absolute values of the weights to the loss function. \n",
    "    # This can encourage the model to prefer solutions where many weights are exactly zero.\n",
    "    regularization_term = sum(tf.reduce_sum(tf.abs(w)) for w in weights.values())\n",
    "    \n",
    "    # print(f'output = {output}')\n",
    "    # print('tf.square(output) = ', tf.square(output))\n",
    "\n",
    "    # Mean squared error loss\n",
    "    mse_loss = tf.reduce_mean(tf.square(output))\n",
    "    \n",
    "    # print(f'mse_loss = {mse_loss}')\n",
    "    \n",
    "    \n",
    "\n",
    "    # Total loss with regularization term\n",
    "    total_loss = mse_loss + lambda_reg * regularization_term\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "# Train step\n",
    "def train_step(weights, biases, optimizer, lambda_reg=0.01):\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        \n",
    "        loss = loss_function(weights, biases, lambda_reg=lambda_reg)\n",
    "\n",
    "    trainable_variables = [weights['w12']]  # list containing only 'w12'\n",
    "    \n",
    "    gradients = tape.gradient(loss, trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, trainable_variables))\n",
    "\n",
    "    return loss    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'num_hidden = [21, 68]'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'num_output = 17'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Network Parameters\n",
    "num_input = 1 # input layer\n",
    "\n",
    "num_vars = len(variables)\n",
    "num_eqs = len(equations)\n",
    "num_functions = len(functions)\n",
    "\n",
    "num_hidden = [num_vars, num_functions]\n",
    "num_output = num_eqs # output layer\n",
    "\n",
    "display(\n",
    "    f'num_hidden = {num_hidden}',\n",
    "    f'num_output = {num_output}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading most recent estimate from ERK_equations_s6p5/best_estimate_231118_132718.json\n"
     ]
    }
   ],
   "source": [
    "## Weights to Layer 3 - determined by the functions contains the variables\n",
    "w23_flags = [[True] * num_functions for _ in range(num_vars)]\n",
    "for vi, var in enumerate(variables):\n",
    "    for fi, func in enumerate(functions):\n",
    "        # print(f'var = {var}, func = {func} var not in func = {var not in func}')\n",
    "        if var not in func:\n",
    "            w23_flags[vi][fi] = False\n",
    "\n",
    "w23_flags = tf.constant(w23_flags, dtype=tf.bool)\n",
    "\n",
    "# Initialize the weights (w23) with zeros\n",
    "w23 = tf.constant(tf.zeros(num_hidden, dtype=tf_precision))\n",
    "# Set the weights to 1 where func_flags is True\n",
    "w23 = tf.where(w23_flags, tf.ones_like(w23), w23)\n",
    "w23 = tf.transpose(w23)\n",
    "\n",
    "## Weights to Layer 4 - determined by the coefficients of the functions\n",
    "# Initialize the weights (w34) with zeros\n",
    "w34_np = np.zeros([num_functions, num_output], dtype=np_precision)\n",
    "# Assign scalar coefficients to the first column of w34_np\n",
    "row = 0\n",
    "for sci, scalar_coeffs in enumerate(scalar_coefficients):\n",
    "    for scj, scl_coeff in enumerate(scalar_coeffs):\n",
    "        w34_np[row, sci] = scl_coeff\n",
    "        row += 1\n",
    "# Tranform to tensor\n",
    "w34 = tf.constant(w34_np, dtype=tf_precision)\n",
    "\n",
    "if load_initial_estimate is None:\n",
    "    w12 = tf.Variable(tf.random.normal([num_input, num_hidden[0]], dtype=tf_precision), \n",
    "                      dtype=tf_precision, \n",
    "                      constraint=NonNeg())\n",
    "    \n",
    "    initial_solution = w12.numpy()[0].tolist()\n",
    "    \n",
    "elif isinstance(load_initial_estimate, str):\n",
    "    print('Loading initial estimate...')\n",
    "    # Load json file with initial estimate (best from the previous run)\n",
    "    with open(os.path.join(problem_name, f'{load_initial_estimate}.json'), 'r') as file:\n",
    "        data = json.load(file)\n",
    "    init_estimate = data['best_solution']\n",
    "    initial_solution = [float(x) for x in init_estimate.values()]\n",
    "    w12 = tf.Variable(tf.constant([initial_solution], dtype=tf_precision), constraint=NonNeg())\n",
    "\n",
    "elif load_initial_estimate == True:\n",
    "    init_estimate = load_most_recent_estimate(problem_name)\n",
    "    \n",
    "    if init_estimate is not None:\n",
    "        initial_solution = [float(x) for x in init_estimate.values()]\n",
    "        w12 = tf.Variable(tf.constant([initial_solution], dtype=tf_precision), constraint=NonNeg())\n",
    "    else:\n",
    "        w12 = tf.Variable(tf.random.normal([num_input, num_hidden[0]], dtype=tf_precision), \n",
    "                          dtype=tf_precision, \n",
    "                          constraint=NonNeg())\n",
    "        initial_solution = w12.numpy()[0].tolist()\n",
    "    \n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    ## Variables - weights to Layer 1\n",
    "    # Create the variable with the non-negativity constraint\n",
    "    'w12': w12,\n",
    "    # Whether the functions in F1 and F2 contain the variables x1 and x2\n",
    "    'w23': w23,\n",
    "    # # The coefficients of the functions in F1 and F2\n",
    "    'w34': w34\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'b12': tf.constant(tf.zeros([num_hidden[0]], dtype=tf_precision)),\n",
    "    'b23': tf.constant(tf.zeros([num_hidden[1]], dtype=tf_precision)),\n",
    "    'out': tf.constant([bias_coefficients], dtype=tf_precision),\n",
    "}\n",
    "\n",
    "# Stochastic gradient descent optimizer.\n",
    "optimizer = Adam(learning_rate=learning_rate, name='custom_optimizer_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b_1 + b_2 + b_3 + b_4 + b_5 + b_6 - 1,\n",
       " 2*a_21*b_2 + 2*b_3*(a_31 + a_32) + 2*b_4*(a_41 + a_42 + a_43) + 2*b_5*(a_51 + a_52 + a_53 + a_54) + 2*b_6*(a_61 + a_62 + a_63 + a_64 + a_65) - 1,\n",
       " 6*a_21*a_32*b_3 + 6*b_4*(a_21*a_42 + a_43*(a_31 + a_32)) + 6*b_5*(a_21*a_52 + a_53*(a_31 + a_32) + a_54*(a_41 + a_42 + a_43)) + 6*b_6*(a_21*a_62 + a_63*(a_31 + a_32) + a_64*(a_41 + a_42 + a_43) + a_65*(a_51 + a_52 + a_53 + a_54)) - 1,\n",
       " 3*a_21**2*b_2 + 3*b_3*(a_31 + a_32)**2 + 3*b_4*(a_41 + a_42 + a_43)**2 + 3*b_5*(a_51 + a_52 + a_53 + a_54)**2 + 3*b_6*(a_61 + a_62 + a_63 + a_64 + a_65)**2 - 1,\n",
       " 24*a_21*a_32*a_43*b_4 + 24*b_5*(a_21*a_32*a_53 + a_54*(a_21*a_42 + a_43*(a_31 + a_32))) + 24*b_6*(a_21*a_32*a_63 + a_64*(a_21*a_42 + a_43*(a_31 + a_32)) + a_65*(a_21*a_52 + a_53*(a_31 + a_32) + a_54*(a_41 + a_42 + a_43))) - 1,\n",
       " 12*a_21**2*a_32*b_3 + 12*b_4*(a_21**2*a_42 + a_43*(a_31 + a_32)**2) + 12*b_5*(a_21**2*a_52 + a_53*(a_31 + a_32)**2 + a_54*(a_41 + a_42 + a_43)**2) + 12*b_6*(a_21**2*a_62 + a_63*(a_31 + a_32)**2 + a_64*(a_41 + a_42 + a_43)**2 + a_65*(a_51 + a_52 + a_53 + a_54)**2) - 1,\n",
       " 8*a_21*a_32*b_3*(a_31 + a_32) + 8*b_4*(a_21*a_42 + a_43*(a_31 + a_32))*(a_41 + a_42 + a_43) + 8*b_5*(a_21*a_52 + a_53*(a_31 + a_32) + a_54*(a_41 + a_42 + a_43))*(a_51 + a_52 + a_53 + a_54) + 8*b_6*(a_21*a_62 + a_63*(a_31 + a_32) + a_64*(a_41 + a_42 + a_43) + a_65*(a_51 + a_52 + a_53 + a_54))*(a_61 + a_62 + a_63 + a_64 + a_65) - 1,\n",
       " 4*a_21**3*b_2 + 4*b_3*(a_31 + a_32)**3 + 4*b_4*(a_41 + a_42 + a_43)**3 + 4*b_5*(a_51 + a_52 + a_53 + a_54)**3 + 4*b_6*(a_61 + a_62 + a_63 + a_64 + a_65)**3 - 1,\n",
       " 120*a_21*a_32*a_43*a_54*b_5 + 120*b_6*(a_21*a_32*a_43*a_64 + a_65*(a_21*a_32*a_53 + a_54*(a_21*a_42 + a_43*(a_31 + a_32)))) - 1,\n",
       " 60*a_21**2*a_32*a_43*b_4 + 60*b_5*(a_21**2*a_32*a_53 + a_54*(a_21**2*a_42 + a_43*(a_31 + a_32)**2)) + 60*b_6*(a_21**2*a_32*a_63 + a_64*(a_21**2*a_42 + a_43*(a_31 + a_32)**2) + a_65*(a_21**2*a_52 + a_53*(a_31 + a_32)**2 + a_54*(a_41 + a_42 + a_43)**2)) - 1,\n",
       " 40*a_21*a_32*a_43*b_4*(a_31 + a_32) + 40*b_5*(a_21*a_32*a_53*(a_31 + a_32) + a_54*(a_21*a_42 + a_43*(a_31 + a_32))*(a_41 + a_42 + a_43)) + 40*b_6*(a_21*a_32*a_63*(a_31 + a_32) + a_64*(a_21*a_42 + a_43*(a_31 + a_32))*(a_41 + a_42 + a_43) + a_65*(a_21*a_52 + a_53*(a_31 + a_32) + a_54*(a_41 + a_42 + a_43))*(a_51 + a_52 + a_53 + a_54)) - 1,\n",
       " 30*a_21*a_32*a_43*b_4*(a_41 + a_42 + a_43) + 30*b_5*(a_21*a_32*a_53 + a_54*(a_21*a_42 + a_43*(a_31 + a_32)))*(a_51 + a_52 + a_53 + a_54) + 30*b_6*(a_21*a_32*a_63 + a_64*(a_21*a_42 + a_43*(a_31 + a_32)) + a_65*(a_21*a_52 + a_53*(a_31 + a_32) + a_54*(a_41 + a_42 + a_43)))*(a_61 + a_62 + a_63 + a_64 + a_65) - 1,\n",
       " 20*a_21**3*a_32*b_3 + 20*b_4*(a_21**3*a_42 + a_43*(a_31 + a_32)**3) + 20*b_5*(a_21**3*a_52 + a_53*(a_31 + a_32)**3 + a_54*(a_41 + a_42 + a_43)**3) + 20*b_6*(a_21**3*a_62 + a_63*(a_31 + a_32)**3 + a_64*(a_41 + a_42 + a_43)**3 + a_65*(a_51 + a_52 + a_53 + a_54)**3) - 1,\n",
       " 15*a_21**2*a_32*b_3*(a_31 + a_32) + 15*b_4*(a_21**2*a_42 + a_43*(a_31 + a_32)**2)*(a_41 + a_42 + a_43) + 15*b_5*(a_21**2*a_52 + a_53*(a_31 + a_32)**2 + a_54*(a_41 + a_42 + a_43)**2)*(a_51 + a_52 + a_53 + a_54) + 15*b_6*(a_21**2*a_62 + a_63*(a_31 + a_32)**2 + a_64*(a_41 + a_42 + a_43)**2 + a_65*(a_51 + a_52 + a_53 + a_54)**2)*(a_61 + a_62 + a_63 + a_64 + a_65) - 1,\n",
       " 20*a_21**2*a_32**2*b_3 + 20*b_4*(a_21*a_42 + a_43*(a_31 + a_32))**2 + 20*b_5*(a_21*a_52 + a_53*(a_31 + a_32) + a_54*(a_41 + a_42 + a_43))**2 + 20*b_6*(a_21*a_62 + a_63*(a_31 + a_32) + a_64*(a_41 + a_42 + a_43) + a_65*(a_51 + a_52 + a_53 + a_54))**2 - 1,\n",
       " 10*a_21*a_32*b_3*(a_31 + a_32)**2 + 10*b_4*(a_21*a_42 + a_43*(a_31 + a_32))*(a_41 + a_42 + a_43)**2 + 10*b_5*(a_21*a_52 + a_53*(a_31 + a_32) + a_54*(a_41 + a_42 + a_43))*(a_51 + a_52 + a_53 + a_54)**2 + 10*b_6*(a_21*a_62 + a_63*(a_31 + a_32) + a_64*(a_41 + a_42 + a_43) + a_65*(a_51 + a_52 + a_53 + a_54))*(a_61 + a_62 + a_63 + a_64 + a_65)**2 - 1,\n",
       " 5*a_21**4*b_2 + 5*b_3*(a_31 + a_32)**4 + 5*b_4*(a_41 + a_42 + a_43)**4 + 5*b_5*(a_51 + a_52 + a_53 + a_54)**4 + 5*b_6*(a_61 + a_62 + a_63 + a_64 + a_65)**4 - 1]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "equations_sym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      0 => loss: 4.8104347616252792e-07 | best loss: 4.8104347616252792e-07 (0)\n",
      "epoch   2500 => loss: 4.7922226584286256e-07 | best loss: 4.7922226584286256e-07 (2500)\n",
      "epoch   5000 => loss: 4.7734121627892422e-07 | best loss: 4.7734121627892422e-07 (5000)\n",
      "epoch   7500 => loss: 4.7549264063862449e-07 | best loss: 4.7549264063862449e-07 (7500)\n",
      "epoch  10000 => loss: 4.7367775402109064e-07 | best loss: 4.7367775402109064e-07 (10000)\n",
      "epoch  12500 => loss: 4.7189353783245656e-07 | best loss: 4.7189353783245656e-07 (12500)\n",
      "epoch  15000 => loss: 4.7013553974365609e-07 | best loss: 4.7013553974365609e-07 (15000)\n",
      "epoch  17500 => loss: 4.6841523750344471e-07 | best loss: 4.6841523750344471e-07 (17500)\n",
      "epoch  20000 => loss: 4.6672576408514734e-07 | best loss: 4.6672576408514734e-07 (20000)\n",
      "epoch  22500 => loss: 4.6550583496099225e-07 | best loss: 4.6550583496099225e-07 (22500)\n",
      "epoch  25000 => loss: 4.6402050018088945e-07 | best loss: 4.6402050018088945e-07 (25000)\n",
      "epoch  27500 => loss: 4.6256144268487058e-07 | best loss: 4.6256144268487058e-07 (27500)\n",
      "epoch  30000 => loss: 4.6112036967586946e-07 | best loss: 4.6112036967586946e-07 (30000)\n",
      "epoch  32500 => loss: 4.5969921539120590e-07 | best loss: 4.5969921539120590e-07 (32500)\n",
      "epoch  35000 => loss: 4.5829565176444392e-07 | best loss: 4.5829565176444392e-07 (35000)\n",
      "epoch  37500 => loss: 4.5690769692633613e-07 | best loss: 4.5690769692633613e-07 (37500)\n",
      "epoch  40000 => loss: 4.5554029799910409e-07 | best loss: 4.5554029799910409e-07 (40000)\n",
      "epoch  42500 => loss: 4.5519134872152088e-07 | best loss: 4.5519134872152088e-07 (42500)\n",
      "epoch  45000 => loss: 4.5479645433225976e-07 | best loss: 4.5479645433225976e-07 (45000)\n",
      "epoch  47500 => loss: 4.5440095957346653e-07 | best loss: 4.5440095957346653e-07 (47500)\n",
      "epoch  50000 => loss: 4.5400834519954583e-07 | best loss: 4.5400834519954583e-07 (50000)\n"
     ]
    }
   ],
   "source": [
    "best_loss = np.inf  # Initialize with infinity or an appropriate initial value\n",
    "\n",
    "# Initialize variables to store the best solution\n",
    "best_solution = None\n",
    "best_epoch = None\n",
    "# # Define the number of epochs after which to save the best weights\n",
    "# save_interval = training_steps // 100    # Every 1% of the training steps \n",
    "\n",
    "lambda_reg = float(config_data['lambda_regularization'])\n",
    "\n",
    "for i in range(training_steps):\n",
    "    \n",
    "    current_loss = train_step(weights, biases, optimizer, lambda_reg=lambda_reg)\n",
    "    \n",
    "    # Check if the current loss is better than the best loss\n",
    "    if current_loss < best_loss:\n",
    "        best_loss = current_loss\n",
    "        best_epoch = i\n",
    "        best_solution = weights['w12'].numpy()[0].copy()\n",
    "       \n",
    "    if i % display_step == 0:\n",
    "        print(f\"epoch {i:6d} => loss: {current_loss:.16e} | best loss: {best_loss:.16e} ({best_epoch})\")\n",
    "        \n",
    "    if current_loss <= 1e-32:\n",
    "        print(f\"epoch {i:6d} => loss: {current_loss:.16e} | best loss: {best_loss:.16e} ({best_epoch})\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save best solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_best_solution is not None:\n",
    "    \n",
    "    best_solution_dict = dict()\n",
    "    initial_solution_dict = dict()\n",
    "    for vi, var in enumerate(variables):\n",
    "        initial_solution_dict[var] = f'{initial_solution[vi]:.16f}'\n",
    "        best_solution_dict[var] = f'{best_solution[vi]:.16f}'\n",
    "        \n",
    "    save_solution_dict = {\n",
    "        'initial_estimate': initial_solution_dict,\n",
    "        'best_solution': best_solution_dict,\n",
    "        'best_epoch': best_epoch,\n",
    "    }\n",
    "        \n",
    "    now = datetime.now()\n",
    "    dt_string = now.strftime(\"%y%m%d %H%M%S\")\n",
    "    save_file_path = os.path.join(problem_name, f'best_estimate_{dt_string.split()[0]}_{dt_string.split()[1]}.json')\n",
    "    \n",
    "    # Save the configuration data to the JSON file\n",
    "    with open(save_file_path, 'w') as config_file:\n",
    "        json.dump(save_solution_dict, config_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST SOLUTION\n",
      "a_21 = 0.2496246776805635\n",
      "a_31 = 0.0329786389138311\n",
      "a_32 = 0.2508332676940005\n",
      "a_41 = 0.0049390560581523\n",
      "a_42 = -0.0000000000000000\n",
      "a_43 = 0.5143848578016184\n",
      "a_51 = 0.1961355905994132\n",
      "a_52 = -0.0000000000000000\n",
      "a_53 = 0.0391650039760012\n",
      "a_54 = 0.5331951217476733\n",
      "a_61 = 0.0578762936198704\n",
      "a_62 = 0.2838071349834700\n",
      "a_63 = 0.2052286658160081\n",
      "a_64 = -0.0000000000000000\n",
      "a_65 = 0.3356539652211482\n",
      "b_1 = 0.0818732870180934\n",
      "b_2 = 0.1656477904136298\n",
      "b_3 = 0.1968653960881361\n",
      "b_4 = 0.2051305328556744\n",
      "b_5 = 0.1138000560782289\n",
      "b_6 = 0.2366828855639300\n",
      "\n",
      "RESIDUALS\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------+---------------------+\n",
      "| Equation                                                                                                                                                                                                                                                                                                                                                              |   Model residual |   Function residual |\n",
      "+=======================================================================================================================================================================================================================================================================================================================================================================+==================+=====================+\n",
      "| b_1 + b_2 + b_3 + b_4 + b_5 + b_6 - 1 =                                                                                                                                                                                                                                                                                                                               |       5.1982e-08 |          5.1982e-08 |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------+---------------------+\n",
      "| 2*a_21*b_2 + 2*b_3*(a_31 + a_32) + 2*b_4*(a_41 + a_42 + a_43) + 2*b_5*(a_51 + a_52 + a_53 + a_54) + 2*b_6*(a_61 + a_62 + a_63 + a_64 + a_65) - 1 =                                                                                                                                                                                                                    |       0.0001897  |          0.0001897  |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------+---------------------+\n",
      "| 6*a_21*a_32*b_3 + 6*b_4*(a_21*a_42 + a_43*(a_31 + a_32)) + 6*b_5*(a_21*a_52 + a_53*(a_31 + a_32) + a_54*(a_41 + a_42 + a_43)) + 6*b_6*(a_21*a_62 + a_63*(a_31 + a_32) + a_64*(a_41 + a_42 + a_43) + a_65*(a_51 + a_52 + a_53 + a_54)) - 1 =                                                                                                                           |       6.7819e-05 |          6.7819e-05 |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------+---------------------+\n",
      "| 3*a_21^2*b_2 + 3*b_3*(a_31 + a_32)^2 + 3*b_4*(a_41 + a_42 + a_43)^2 + 3*b_5*(a_51 + a_52 + a_53 + a_54)^2 + 3*b_6*(a_61 + a_62 + a_63 + a_64 + a_65)^2 - 1 =                                                                                                                                                                                                          |       0.00079354 |          0.00079354 |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------+---------------------+\n",
      "| 24*a_21*a_32*a_43*b_4 + 24*b_5*(a_21*a_32*a_53 + a_54*(a_21*a_42 + a_43*(a_31 + a_32))) + 24*b_6*(a_21*a_32*a_63 + a_64*(a_21*a_42 + a_43*(a_31 + a_32)) + a_65*(a_21*a_52 + a_53*(a_31 + a_32) + a_54*(a_41 + a_42 + a_43))) - 1 =                                                                                                                                   |       1.8848e-06 |          1.8848e-06 |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------+---------------------+\n",
      "| 12*a_21^2*a_32*b_3 + 12*b_4*(a_21^2*a_42 + a_43*(a_31 + a_32)^2) + 12*b_5*(a_21^2*a_52 + a_53*(a_31 + a_32)^2 + a_54*(a_41 + a_42 + a_43)^2) + 12*b_6*(a_21^2*a_62 + a_63*(a_31 + a_32)^2 + a_64*(a_41 + a_42 + a_43)^2 + a_65*(a_51 + a_52 + a_53 + a_54)^2) - 1 =                                                                                                   |       0.00020382 |          0.00020382 |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------+---------------------+\n",
      "| 8*a_21*a_32*b_3*(a_31 + a_32) + 8*b_4*(a_21*a_42 + a_43*(a_31 + a_32))*(a_41 + a_42 + a_43) + 8*b_5*(a_21*a_52 + a_53*(a_31 + a_32) + a_54*(a_41 + a_42 + a_43))*(a_51 + a_52 + a_53 + a_54) + 8*b_6*(a_21*a_62 + a_63*(a_31 + a_32) + a_64*(a_41 + a_42 + a_43) + a_65*(a_51 + a_52 + a_53 + a_54))*(a_61 + a_62 + a_63 + a_64 + a_65) - 1 =                         |       0.00069661 |          0.00069661 |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------+---------------------+\n",
      "| 4*a_21^3*b_2 + 4*b_3*(a_31 + a_32)^3 + 4*b_4*(a_41 + a_42 + a_43)^3 + 4*b_5*(a_51 + a_52 + a_53 + a_54)^3 + 4*b_6*(a_61 + a_62 + a_63 + a_64 + a_65)^3 - 1 =                                                                                                                                                                                                          |       0.00066076 |          0.00066076 |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------+---------------------+\n",
      "| 120*a_21*a_32*a_43*a_54*b_5 + 120*b_6*(a_21*a_32*a_43*a_64 + a_65*(a_21*a_32*a_53 + a_54*(a_21*a_42 + a_43*(a_31 + a_32)))) - 1 =                                                                                                                                                                                                                                     |       3.6833e-05 |          3.6833e-05 |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------+---------------------+\n",
      "| 60*a_21^2*a_32*a_43*b_4 + 60*b_5*(a_21^2*a_32*a_53 + a_54*(a_21^2*a_42 + a_43*(a_31 + a_32)^2)) + 60*b_6*(a_21^2*a_32*a_63 + a_64*(a_21^2*a_42 + a_43*(a_31 + a_32)^2) + a_65*(a_21^2*a_52 + a_53*(a_31 + a_32)^2 + a_54*(a_41 + a_42 + a_43)^2)) - 1 =                                                                                                               |       1.2758e-05 |          1.2758e-05 |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------+---------------------+\n",
      "| 40*a_21*a_32*a_43*b_4*(a_31 + a_32) + 40*b_5*(a_21*a_32*a_53*(a_31 + a_32) + a_54*(a_21*a_42 + a_43*(a_31 + a_32))*(a_41 + a_42 + a_43)) + 40*b_6*(a_21*a_32*a_63*(a_31 + a_32) + a_64*(a_21*a_42 + a_43*(a_31 + a_32))*(a_41 + a_42 + a_43) + a_65*(a_21*a_52 + a_53*(a_31 + a_32) + a_54*(a_41 + a_42 + a_43))*(a_51 + a_52 + a_53 + a_54)) - 1 =                   |       7.0819e-05 |          7.0819e-05 |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------+---------------------+\n",
      "| 30*a_21*a_32*a_43*b_4*(a_41 + a_42 + a_43) + 30*b_5*(a_21*a_32*a_53 + a_54*(a_21*a_42 + a_43*(a_31 + a_32)))*(a_51 + a_52 + a_53 + a_54) + 30*b_6*(a_21*a_32*a_63 + a_64*(a_21*a_42 + a_43*(a_31 + a_32)) + a_65*(a_21*a_52 + a_53*(a_31 + a_32) + a_54*(a_41 + a_42 + a_43)))*(a_61 + a_62 + a_63 + a_64 + a_65) - 1 =                                               |       5.9429e-05 |          5.9429e-05 |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------+---------------------+\n",
      "| 20*a_21^3*a_32*b_3 + 20*b_4*(a_21^3*a_42 + a_43*(a_31 + a_32)^3) + 20*b_5*(a_21^3*a_52 + a_53*(a_31 + a_32)^3 + a_54*(a_41 + a_42 + a_43)^3) + 20*b_6*(a_21^3*a_62 + a_63*(a_31 + a_32)^3 + a_64*(a_41 + a_42 + a_43)^3 + a_65*(a_51 + a_52 + a_53 + a_54)^3) - 1 =                                                                                                   |       0.00015117 |          0.00015117 |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------+---------------------+\n",
      "| 15*a_21^2*a_32*b_3*(a_31 + a_32) + 15*b_4*(a_21^2*a_42 + a_43*(a_31 + a_32)^2)*(a_41 + a_42 + a_43) + 15*b_5*(a_21^2*a_52 + a_53*(a_31 + a_32)^2 + a_54*(a_41 + a_42 + a_43)^2)*(a_51 + a_52 + a_53 + a_54) + 15*b_6*(a_21^2*a_62 + a_63*(a_31 + a_32)^2 + a_64*(a_41 + a_42 + a_43)^2 + a_65*(a_51 + a_52 + a_53 + a_54)^2)*(a_61 + a_62 + a_63 + a_64 + a_65) - 1 = |       0.00042289 |          0.00042289 |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------+---------------------+\n",
      "| 20*a_21^2*a_32^2*b_3 + 20*b_4*(a_21*a_42 + a_43*(a_31 + a_32))^2 + 20*b_5*(a_21*a_52 + a_53*(a_31 + a_32) + a_54*(a_41 + a_42 + a_43))^2 + 20*b_6*(a_21*a_62 + a_63*(a_31 + a_32) + a_64*(a_41 + a_42 + a_43) + a_65*(a_51 + a_52 + a_53 + a_54))^2 - 1 =                                                                                                             |       0.00077873 |          0.00077873 |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------+---------------------+\n",
      "| 10*a_21*a_32*b_3*(a_31 + a_32)^2 + 10*b_4*(a_21*a_42 + a_43*(a_31 + a_32))*(a_41 + a_42 + a_43)^2 + 10*b_5*(a_21*a_52 + a_53*(a_31 + a_32) + a_54*(a_41 + a_42 + a_43))*(a_51 + a_52 + a_53 + a_54)^2 + 10*b_6*(a_21*a_62 + a_63*(a_31 + a_32) + a_64*(a_41 + a_42 + a_43) + a_65*(a_51 + a_52 + a_53 + a_54))*(a_61 + a_62 + a_63 + a_64 + a_65)^2 - 1 =             |       0.002195   |          0.002195   |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------+---------------------+\n",
      "| 5*a_21^4*b_2 + 5*b_3*(a_31 + a_32)^4 + 5*b_4*(a_41 + a_42 + a_43)^4 + 5*b_5*(a_51 + a_52 + a_53 + a_54)^4 + 5*b_6*(a_61 + a_62 + a_63 + a_64 + a_65)^4 - 1 =                                                                                                                                                                                                          |       0.00066952 |          0.00066952 |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "func_res_model, solution  = multilayer_perceptron(weights, biases)\n",
    "solution = list(solution.numpy()[0])\n",
    "best_solution = list(best_solution)\n",
    "\n",
    "print('BEST SOLUTION')\n",
    "for i, var in enumerate(variables):\n",
    "    print(f'{var} = {best_solution[i]:.16f}')\n",
    "    \n",
    "print()\n",
    "print('RESIDUALS')\n",
    "headers = ['Equation', 'Model residual', 'Function residual']\n",
    "# headers = ['Equation', 'Function residual']\n",
    "table_data = []\n",
    "\n",
    "for f, func in enumerate(equations):\n",
    "    eq = equations_sym[f]\n",
    "    equation = lambdify(variables_sym, eq)\n",
    "    func_res_eq = abs(equation(*best_solution))\n",
    "    table_data.append([f'{func} = ', f'{abs(func_res_model[0, f]):.4e}', f'{func_res_eq:.4e}'])\n",
    "    # table_data.append([f'{func} = ', f'{func_res_eq:.4e}'])\n",
    "\n",
    "print(tabulate(table_data, headers=headers, tablefmt='grid'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-nn-systems",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
