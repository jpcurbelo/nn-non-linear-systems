{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-09 12:37:04.612962: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-09 12:37:04.615296: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-09 12:37:04.657613: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-09 12:37:04.657653: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-09 12:37:04.657681: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-09 12:37:04.664763: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-09 12:37:04.665488: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-09 12:37:05.563162: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from sympy import symbols, sympify, lambdify\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.constraints import NonNeg\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "seed_value = 2023\n",
    "tf.random.set_seed(seed_value)\n",
    "np.random.seed(seed_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EQS_FILE = 'ERK_equations_s2p2.json'\n",
    "# EQS_FILE = 'ERK_equations_s4p4.json'\n",
    "EQS_FILE = 'vicky_case2.json'\n",
    "\n",
    "EQS_PATH = os.path.join(os.getcwd(), 'RK_rootedtrees', EQS_FILE)\n",
    "\n",
    "\n",
    "training_steps = 2001  #   5000 + 1\n",
    "display_step = training_steps // 10\n",
    "\n",
    "# learning_rate = 1e-2\n",
    "learning_rate = tf.keras.optimizers.schedules.PiecewiseConstantDecay([training_steps // 3, 2 * training_steps // 3],[1e-2,5e-3,1e-3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "equation_terms = [['-1', 'a1', 'a2', 'a3', 'a4'], ['-1', 'b1', 'b2', 'b3', 'b4'], ['-1', 'c1', 'c2', 'c3', 'c4'], ['-1', 'd1', 'd2', 'd3', 'd4'], ['-0.5', 'a2*b1', 'a3*(b1+b2)', 'a4*(b1+b2+b3)'], ['-0.5', 'a2*c1', 'a3*(c1+c2)', 'a4*(c1+c2+c3)'], ['-0.5', 'a2*d1', 'a3*(d1+d2)', 'a4*(d1+d2+d3)'], ['-0.5', 'b2*c1', 'b3*(c1+c2)', 'b4*(c1+c2+c3)'], ['-0.5', 'b2*d1', 'b3*(d1+d2)', 'b4*(d1+d2+d3)'], ['-0.5', 'c2*d1', 'c3*(d1+d2)', 'c4*(d1+d2+d3)']]\n",
      "[-1.0, -1.0, -1.0, -1.0, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5]\n",
      "[[1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0, 1.0]]\n",
      "['a1', 'a2', 'a3', 'a4', 'b1', 'b2', 'b3', 'b4', 'c1', 'c2', 'c3', 'c4', 'd1', 'd2', 'd3', 'd4', 'b1', '(b1+b2)', '(b1+b2+b3)', 'c1', '(c1+c2)', '(c1+c2+c3)', 'd1', '(d1+d2)', '(d1+d2+d3)', 'c1', '(c1+c2)', '(c1+c2+c3)', 'd1', '(d1+d2)', '(d1+d2+d3)', 'd1', '(d1+d2)', '(d1+d2+d3)']\n"
     ]
    }
   ],
   "source": [
    "# Read the JSON data from the file\n",
    "with open(EQS_PATH, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "variables = data['variables']\n",
    "equations = data['equations']\n",
    "equation_terms = data['equation_terms']\n",
    "\n",
    "# display(\n",
    "#     f'variables = {variables}',\n",
    "#     f'equations = {equations}',\n",
    "#     f'equation_terms = {equation_terms}'\n",
    "# )\n",
    "\n",
    "print(f'equation_terms = {equation_terms}')\n",
    "\n",
    "# Initialize a list to store the coefficients\n",
    "scalar_coefficients = []\n",
    "functions = []\n",
    "bias_coefficients = []\n",
    "\n",
    "# Loop through the equation terms\n",
    "for terms in equation_terms:\n",
    "    bias_coefficients.append(float(terms[0]))\n",
    "    coefficients = []   \n",
    "    for term in terms[1:]:\n",
    "        # Split each term by the first '*'\n",
    "        term_parts = term.split('*')\n",
    "        # Extract the scalar coefficient or default to '1'\n",
    "        scalar_coeff = term_parts[0] if len(term_parts) > 1 and term_parts[0] not in variables else '1'\n",
    "        coefficients.append(float(scalar_coeff))\n",
    "               \n",
    "        # Remove first occurrence of scalar coefficient from the term\n",
    "        func_coeff = term.replace(term_parts[0]+'*', '', 1) if len(term_parts) > 1 else term\n",
    "        functions.append(func_coeff)\n",
    "        \n",
    "    scalar_coefficients.append(coefficients)   \n",
    "        \n",
    "print(bias_coefficients)\n",
    "print(scalar_coefficients)\n",
    "print(functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'num_hidden = [16, 34]'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'num_output = 10'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Network Parameters\n",
    "num_input = 1 # input layer\n",
    "\n",
    "num_vars = len(variables)\n",
    "num_eqs = len(equations)\n",
    "num_functions = len(functions)\n",
    "\n",
    "num_hidden = [num_vars, num_functions]\n",
    "num_output = num_eqs # output layer\n",
    "\n",
    "display(\n",
    "    f'num_hidden = {num_hidden}',\n",
    "    f'num_output = {num_output}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Weights to Layer 3 - determined by the functions contains the variables\n",
    "w23_flags = [[True] * num_functions for _ in range(num_vars)]\n",
    "for vi, var in enumerate(variables):\n",
    "    for fi, func in enumerate(functions):\n",
    "        # print(f'var = {var}, func = {func}', var not in func)\n",
    "        if var not in func:\n",
    "            w23_flags[vi][fi] = False\n",
    "\n",
    "w23_flags = tf.constant(w23_flags, dtype=tf.bool)\n",
    "\n",
    "# Initialize the weights (w23) with zeros\n",
    "w23 = tf.constant(tf.zeros(num_hidden, dtype=tf.float32))\n",
    "# Set the weights to 1 where func_flags is True\n",
    "w23 = tf.where(w23_flags, tf.ones_like(w23), w23)\n",
    "w23 = tf.transpose(w23)\n",
    "\n",
    "## Weights to Layer 4 - determined by the coefficients of the functions\n",
    "# Initialize the weights (w34) with zeros\n",
    "w34_np = np.zeros([num_functions, num_output], dtype=np.float32)\n",
    "# Assign scalar coefficients to the first column of w34_np\n",
    "row = 0\n",
    "for sci, scalar_coeffs in enumerate(scalar_coefficients):\n",
    "    for scj, scl_coeff in enumerate(scalar_coeffs):\n",
    "        w34_np[row, sci] = scl_coeff\n",
    "        row += 1\n",
    "# Tranform to tensor\n",
    "w34 = tf.constant(w34_np, dtype=tf.float32)\n",
    "\n",
    "## IC for classic methods\n",
    "# w12_rk2 = tf.Variable([[0.8, 0.3, 0.3]])\n",
    "# w12_rk4 = tf.Variable([[0.3, -0.1, 0.63, 0.2, 0.1, 0.8, 0.1, 0.2, 0.4, 0.1]])\n",
    "w12_vicky = tf.Variable([[0.0, 0.0, 0.0, 1.5, 0.0, 0.0, 0.8, 0.8, 0.0, 0.8, 0.0, 0.9, 0.2, 0.0, 0.0, 1.0]],\n",
    "                dtype=tf.float32, \n",
    "                constraint=NonNeg())\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    ## Variables - weights to Layer 1\n",
    "    # Create the variable with the non-negativity constraint\n",
    "    # 'w12': tf.Variable(tf.random.normal([num_input, num_hidden[0]]), \n",
    "    #               dtype=tf.float32, \n",
    "    #               constraint=NonNeg()),\n",
    "    # 'w12': w12_rk2,\n",
    "    # 'w12': w12_rk4,\n",
    "    'w12': w12_vicky,\n",
    "    # Whether the functions in F1 and F2 contain the variables x1 and x2\n",
    "    'w23': w23,\n",
    "    # # The coefficients of the functions in F1 and F2\n",
    "    'w34': w34\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'b12': tf.constant(tf.zeros([num_hidden[0]], dtype=tf.float32)),\n",
    "    'b23': tf.constant(tf.zeros([num_hidden[1]], dtype=tf.float32)),\n",
    "    'out': tf.constant([bias_coefficients], dtype=tf.float32),\n",
    "}\n",
    "\n",
    "# Stochastic gradient descent optimizer.\n",
    "optimizer = Adam(learning_rate=learning_rate, name='custom_optimizer_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_str = ' '.join(variables)\n",
    "variables_sym = symbols(variables_str)\n",
    "functions_sym = [sympify(func) for func in functions]   \n",
    "\n",
    "\n",
    "def evaluate_tf_function(inputs, values, symbolic_function):\n",
    "    # Ensure that the number of inputs and values match\n",
    "    if len(inputs) != len(values):\n",
    "        raise ValueError(\"Number of inputs and values must match.\")\n",
    "\n",
    "    # Evaluate the symbolic function using TensorFlow and the provided values\n",
    "    result = symbolic_function(*values)\n",
    "    # Convert the result to a TensorFlow tensor\n",
    "    result = tf.convert_to_tensor(result, dtype=tf.float32)\n",
    "    \n",
    "    # print(result.__class__)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Define the custom activation function with @tf.function\n",
    "# @tf.function\n",
    "def activation_layer2(layer, vars=variables_sym, funcs=functions_sym):\n",
    "    \n",
    "    layer_values = layer.numpy()[0]\n",
    "    # var_vals = [layer_values[i] for i in range(layer_values.shape[0])]\n",
    "    ##x1_val = tf.squeeze(layer[0, 0])\n",
    "    var_vals = [tf.squeeze(layer[0, i]) for i in range(layer_values.shape[0])]\n",
    "    \n",
    "    # print(f'var_vals = {var_vals}')\n",
    "   \n",
    "    # var_vals_dict = dict(zip(vars, var_vals))\n",
    "    # print(f'var_vals_dict = {var_vals_dict}')\n",
    "    # # Step 3 and 4: Substitute values into the functions and evaluate\n",
    "    # layer_act = [func.subs(var_vals_dict).evalf() for func in funcs]\n",
    "    # # Convert SymPy Float to Python float\n",
    "    # layer_act = [tf.convert_to_tensor(float(val.evalf()), dtype=tf.float32) for val in layer_act]\n",
    "    \n",
    "    layer_act = list()\n",
    "    for func in funcs:\n",
    "        func_tf = lambdify(vars, func, 'tensorflow')\n",
    "        layer_act.append(evaluate_tf_function(variables_sym, var_vals, func_tf))\n",
    "        # result = func_tf(*var_vals)\n",
    "        # layer_act.append(result)\n",
    "    \n",
    "    # print(f'layer_act = {layer_act}')\n",
    "    \n",
    "    # layer_2 = tf.stack(layer_act, axis=0)  # Stack the list of tensors into a single tensor\n",
    "    # layer_2 = tf.reshape(layer_2, [1, len(funcs)])\n",
    "    \n",
    "    # Convert layer_act to a TensorFlow tensor\n",
    "    layer_2 = tf.convert_to_tensor(layer_act, dtype=tf.float32)\n",
    "    \n",
    "    # print(type(layer_2))\n",
    "    \n",
    "    # print(f'layer_2 = {layer_2}')\n",
    "    \n",
    "    layer_2 = tf.reshape(layer_2, [1, len(funcs)])\n",
    "\n",
    "    return layer_2\n",
    "\n",
    "\n",
    "# Create model\n",
    "def multilayer_perceptron(x, weights, biases):\n",
    "\n",
    "    # Reshape input if necessary, matching the shape of the first layer's weights\n",
    "    x = tf.reshape(x, [1, -1])  # Adjust the shape as needed\n",
    "\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['w12']), biases['b12'])\n",
    "    \n",
    "    # print(f'layer_1 = {layer_1.shape}')\n",
    "\n",
    "    layer_2 = activation_layer2(layer_1)\n",
    "    \n",
    "    # Output fully connected layer\n",
    "    output = tf.add(tf.matmul(layer_2, weights['w34']), biases['out'])\n",
    "    \n",
    "    return output, layer_1\n",
    "\n",
    "\n",
    "def loss_function(weights, biases):\n",
    "    \n",
    "    output, _= multilayer_perceptron(tf.constant(1.0, dtype=tf.float32), weights, biases)\n",
    "\n",
    "    return tf.reduce_mean(tf.square(output))\n",
    "\n",
    "\n",
    "# Train step\n",
    "def train_step(weights, biases, optimizer):\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        \n",
    "        loss = loss_function(weights, biases)\n",
    "\n",
    "    trainable_variables = [weights['w12']]  # list containing only 'w12'\n",
    "    \n",
    "    gradients = tape.gradient(loss, trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, trainable_variables))\n",
    "\n",
    "    return loss    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 => loss: 3.6800003051757812e-01 \n",
      "epoch 500 => loss: 2.8421709853920481e-15 \n"
     ]
    }
   ],
   "source": [
    "for i in range(training_steps):\n",
    "       \n",
    "    current_loss = train_step(weights, biases, optimizer)\n",
    "    if i % display_step == 0:\n",
    "        print(f\"epoch {i} => loss: {current_loss:.16e} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOLUTION\n",
      "a1 = 0.2979925275\n",
      "a2 = 0.0023647952\n",
      "a3 = 0.0023647952\n",
      "a4 = 0.6972779036\n",
      "b1 = 0.0200530048\n",
      "b2 = 0.0963397101\n",
      "b3 = 0.2471616268\n",
      "b4 = 0.6364454627\n",
      "c1 = 0.0000000000\n",
      "c2 = 0.0000000000\n",
      "c3 = 0.5000002980\n",
      "c4 = 0.4999996722\n",
      "d1 = 0.0802226365\n",
      "d2 = 0.0000091307\n",
      "d3 = 0.2593138814\n",
      "d4 = 0.6604542732\n",
      "\n",
      "RESIDUALS\n",
      "a1 + a2 + a3 + a4 - 1 = 0.0000e+00\n",
      "b1 + b2 + b3 + b4 - 1 = -1.7881e-07\n",
      "c1 + c2 + c3 + c4 - 1 = 0.0000e+00\n",
      "d1 + d2 + d3 + d4 - 1 = -5.9605e-08\n",
      "a2*b1 + a3*(b1+b2) + a4(b1+b2+b3) - 0.5 = 5.9605e-08\n",
      "a2*c1 + a3*(c1+c2) + a4(c1+c2+c3) - 0.5 = 2.9802e-07\n",
      "a2*d1 + a3*(d1+d2) + a4(d1+d2+d3) - 0.5 = 5.9605e-08\n",
      "b2*c1 + b3*(c1+c2) + b4(c1+c2+c3) - 0.5 = 2.9802e-07\n",
      "b2*d1 + b3*(d1+d2) + b4(d1+d2+d3) - 0.5 = 5.9605e-08\n",
      "c2*d1 + c3*(d1+d2) + c4(d1+d2+d3) - 0.5 = 5.9605e-08\n"
     ]
    }
   ],
   "source": [
    "FUNC_RES, solution  = multilayer_perceptron(tf.constant(1.0, dtype=tf.float32), weights, biases)\n",
    "\n",
    "print('SOLUTION')\n",
    "for i, var in enumerate(variables):\n",
    "    print(f'{var} = {solution[0, i]:.10f}')\n",
    "    \n",
    "print()\n",
    "print('RESIDUALS')\n",
    "for f, func in enumerate(equations):\n",
    "    print(f'{func} = {FUNC_RES[0, f]:.4e}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-nn-systems",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
