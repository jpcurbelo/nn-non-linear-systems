{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-15 11:28:27.241219: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-15 11:28:27.243269: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-15 11:28:27.289447: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-15 11:28:27.289507: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-15 11:28:27.289552: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-15 11:28:27.301407: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-15 11:28:27.301980: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-15 11:28:28.238390: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from sympy import symbols, sympify, lambdify\n",
    "from tabulate import tabulate\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.constraints import NonNeg\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "seed_value = 2023\n",
    "tf.random.set_seed(seed_value)\n",
    "np.random.seed(seed_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e-07"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.backend.epsilon()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_precision = tf.float64\n",
    "np_precision = np.float64\n",
    "\n",
    "\n",
    "with open('config_run.yml', 'r') as ymlfile:\n",
    "    config_data = yaml.load(ymlfile, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_name = config_data['problem_folder']\n",
    "EQS_FILE = problem_name + '.json'\n",
    "EQS_PATH = os.path.join(os.getcwd(), problem_name, EQS_FILE)\n",
    "\n",
    "training_steps = config_data['epochs']\n",
    "display_step = training_steps // 10\n",
    "\n",
    "load_initial_estimate = config_data['load_initial_estimate']\n",
    "save_best_solution = config_data['save_best_solution']\n",
    "\n",
    "# learning_rate = 1e-2\n",
    "# learning_rate = tf.keras.optimizers.schedules.PiecewiseConstantDecay([training_steps // 2],[1e-2, 1e-3])\n",
    "# learning_rate = tf.keras.optimizers.schedules.PiecewiseConstantDecay([training_steps // 3, 2 * training_steps // 3],[1e-1,1e-2,1e-3])\n",
    "# learning_rate = tf.keras.optimizers.schedules.PiecewiseConstantDecay([training_steps // 3, 2 * training_steps // 3],[1e-2,5e-3,1e-3])\n",
    "# learning_rate = tf.keras.optimizers.schedules.PiecewiseConstantDecay([training_steps // 3, 2 * training_steps // 3],[5e-2,1e-2,5e-3])\n",
    "\n",
    "if len(list(config_data['learning_rate'].keys())) > 1:\n",
    "    lr_steps = [int(training_steps * key / 100) for key in list(config_data['learning_rate'].keys()) if key != 0]\n",
    "    lr_values = [float(val) for val in list(config_data['learning_rate'].values())]\n",
    "    learning_rate = tf.keras.optimizers.schedules.PiecewiseConstantDecay(lr_steps, lr_values)\n",
    "else:\n",
    "    learning_rate = float(list(config_data['learning_rate'].values())[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "[[1.0, 1.0, 1.0, 1.0], [2.0, 2.0, 2.0], [6.0, 6.0], [3.0, 3.0, 3.0], [24.0], [12.0, 12.0], [8.0, 8.0], [4.0, 4.0, 4.0]]\n",
      "['b_1', 'b_2', 'b_3', 'b_4', 'a_21*b_2', 'b_3*(a_31 + a_32)', 'b_4*(a_41 + a_42 + a_43)', 'b_4*(a_21*a_42 + a_43*(a_31 + a_32))', 'a_21*a_32*b_3', 'a_21**2*b_2', 'b_3*(a_31 + a_32)**2', 'b_4*(a_41 + a_42 + a_43)**2', 'a_21*a_32*a_43*b_4', 'b_4*(a_21**2*a_42 + a_43*(a_31 + a_32)**2)', 'a_21**2*a_32*b_3', 'b_4*(a_21*a_42 + a_43*(a_31 + a_32))*(a_41 + a_42 + a_43)', 'a_21*a_32*b_3*(a_31 + a_32)', 'a_21**3*b_2', 'b_3*(a_31 + a_32)**3', 'b_4*(a_41 + a_42 + a_43)**3']\n",
      "[b_1, b_2, b_3, b_4, a_21*b_2, b_3*(a_31 + a_32), b_4*(a_41 + a_42 + a_43), b_4*(a_21*a_42 + a_43*(a_31 + a_32)), a_21*a_32*b_3, a_21**2*b_2, b_3*(a_31 + a_32)**2, b_4*(a_41 + a_42 + a_43)**2, a_21*a_32*a_43*b_4, b_4*(a_21**2*a_42 + a_43*(a_31 + a_32)**2), a_21**2*a_32*b_3, b_4*(a_21*a_42 + a_43*(a_31 + a_32))*(a_41 + a_42 + a_43), a_21*a_32*b_3*(a_31 + a_32), a_21**3*b_2, b_3*(a_31 + a_32)**3, b_4*(a_41 + a_42 + a_43)**3]\n"
     ]
    }
   ],
   "source": [
    "# Read the JSON data from the file\n",
    "with open(EQS_PATH, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "variables = data['variables']\n",
    "equations = data['equations']\n",
    "# equation_terms = data['equation_terms']\n",
    "\n",
    "variables_str = ' '.join(variables)\n",
    "variables_sym = symbols(variables_str)\n",
    "equations_sym = [sympify(eq) for eq in equations]  \n",
    "\n",
    "## Identify the equation terms\n",
    "equation_terms = []\n",
    "for (i, eq) in enumerate(equations_sym):\n",
    "    terms = []\n",
    "    for term in eq.args:\n",
    "        terms.append(str(term))\n",
    "    equation_terms.append(terms)\n",
    "\n",
    "# Initialize a list to store the coefficients\n",
    "scalar_coefficients = []\n",
    "functions = []\n",
    "bias_coefficients = []\n",
    "\n",
    "# Loop through the equation terms\n",
    "for terms in equation_terms:\n",
    "    bias_coefficients.append(float(terms[0]))\n",
    "    coefficients = []   \n",
    "    for term in terms[1:]:\n",
    "        # Split each term by the first '*'\n",
    "        term_parts = term.split('*')\n",
    "        # Extract the scalar coefficient or default to '1'\n",
    "        scalar_coeff = term_parts[0] if len(term_parts) > 1 and term_parts[0] not in variables else '1.0'\n",
    "        coefficients.append(float(scalar_coeff))\n",
    "               \n",
    "        # Remove first occurrence of scalar coefficient from the term\n",
    "        func_coeff = term.replace(term_parts[0]+'*', '', 1) if len(term_parts) > 1 and term_parts[0] not in variables else term\n",
    "        functions.append(func_coeff)\n",
    "        \n",
    "    scalar_coefficients.append(coefficients)   \n",
    "       \n",
    "functions_sym = [sympify(func) for func in functions]       \n",
    "        \n",
    "print(bias_coefficients)\n",
    "print(scalar_coefficients)\n",
    "print(functions)\n",
    "print(functions_sym)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_most_recent_estimate(problem_name, prefix=\"best_estimate\"):\n",
    "    # Find all JSON files with the specified prefix\n",
    "    pattern = os.path.join(problem_name, f\"{prefix}_*.json\")\n",
    "    files = glob.glob(pattern)\n",
    "\n",
    "    if not files:\n",
    "        print(f\"No files found with prefix '{prefix}'\")\n",
    "        return None\n",
    "\n",
    "    # Get the most recent file based on modification time\n",
    "    most_recent_file = max(files, key=os.path.getmtime)\n",
    "    \n",
    "    print(f\"Loading most recent estimate from {most_recent_file}\")\n",
    "\n",
    "    # Load json file with initial estimate (best from the most recent run)\n",
    "    with open(most_recent_file, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    return data['best_solution']\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_tf_function(inputs, values, symbolic_function):\n",
    "    # Ensure that the number of inputs and values match\n",
    "    if len(inputs) != len(values):\n",
    "        raise ValueError(\"Number of inputs and values must match.\")\n",
    "\n",
    "    # Evaluate the symbolic function using TensorFlow and the provided values\n",
    "    result = symbolic_function(*values)\n",
    "    # Convert the result to a TensorFlow tensor\n",
    "    result = tf.convert_to_tensor(result, dtype=tf_precision)\n",
    "    \n",
    "    # print(result.__class__)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Define the custom activation function with @tf.function\n",
    "# @tf.function\n",
    "def activation_layer2(layer, vars=variables_sym, funcs=functions_sym):\n",
    "    \n",
    "    layer_values = layer.numpy()[0]\n",
    "    var_vals = [tf.squeeze(layer[0, i]) for i in range(layer_values.shape[0])]\n",
    "       \n",
    "    layer_act = list()\n",
    "    for func in funcs:\n",
    "        func_tf = lambdify(vars, func, 'tensorflow')\n",
    "        layer_act.append(evaluate_tf_function(variables_sym, var_vals, func_tf))\n",
    "    \n",
    "    # Convert layer_act to a TensorFlow tensor\n",
    "    layer_2 = tf.convert_to_tensor(layer_act, dtype=tf_precision)\n",
    "    layer_2 = tf.reshape(layer_2, [1, len(funcs)])\n",
    "\n",
    "    return layer_2\n",
    "\n",
    "\n",
    "# Create model\n",
    "def multilayer_perceptron(weights, biases):\n",
    "\n",
    "    # # Reshape input if necessary, matching the shape of the first layer's weights\n",
    "    # x = tf.reshape(x, [1, -1])  # Adjust the shape as needed\n",
    "\n",
    "    # layer_1 = tf.add(tf.matmul(x, weights['w12']), biases['b12'])\n",
    "    # layer_1 = tf.matmul(x, weights['w12'])\n",
    "    layer_1 = weights['w12']\n",
    "    \n",
    "    # print(f'layer_1 = {layer_1.shape}')\n",
    "\n",
    "    layer_2 = activation_layer2(layer_1)\n",
    "    \n",
    "    # Output fully connected layer\n",
    "    output = tf.add(tf.matmul(layer_2, weights['w34']), biases['out'])\n",
    "    \n",
    "    # # Add RELU activation function to output layer\n",
    "    # output = tf.nn.relu(output)\n",
    "    \n",
    "    return output, layer_1\n",
    "\n",
    "\n",
    "def loss_function(weights, biases, lambda_reg=0.01):\n",
    "    \n",
    "    output, _ = multilayer_perceptron(weights, biases)\n",
    "    \n",
    "    # # L2 regularization term for weights\n",
    "    # regularization_term = sum(tf.nn.l2_loss(w) for w in weights.values())\n",
    "    \n",
    "    # L1 regularization term for weights - to enforce sparsity\n",
    "    # L1 regularization adds the sum of the absolute values of the weights to the loss function. \n",
    "    # This can encourage the model to prefer solutions where many weights are exactly zero.\n",
    "    regularization_term = sum(tf.reduce_sum(tf.abs(w)) for w in weights.values())\n",
    "\n",
    "    # Mean squared error loss\n",
    "    mse_loss = tf.reduce_mean(tf.square(output))\n",
    "\n",
    "    # Total loss with regularization term\n",
    "    total_loss = mse_loss + lambda_reg * regularization_term\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "# Train step\n",
    "def train_step(weights, biases, optimizer, lambda_reg=0.01):\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        \n",
    "        loss = loss_function(weights, biases, lambda_reg=lambda_reg)\n",
    "\n",
    "    trainable_variables = [weights['w12']]  # list containing only 'w12'\n",
    "    \n",
    "    gradients = tape.gradient(loss, trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, trainable_variables))\n",
    "\n",
    "    return loss    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'num_hidden = [10, 20]'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'num_output = 8'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Network Parameters\n",
    "num_input = 1 # input layer\n",
    "\n",
    "num_vars = len(variables)\n",
    "num_eqs = len(equations)\n",
    "num_functions = len(functions)\n",
    "\n",
    "num_hidden = [num_vars, num_functions]\n",
    "num_output = num_eqs # output layer\n",
    "\n",
    "display(\n",
    "    f'num_hidden = {num_hidden}',\n",
    "    f'num_output = {num_output}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading most recent estimate from ERK_equations_s4p4/best_estimate_231115_111206.json\n"
     ]
    }
   ],
   "source": [
    "## Weights to Layer 3 - determined by the functions contains the variables\n",
    "w23_flags = [[True] * num_functions for _ in range(num_vars)]\n",
    "for vi, var in enumerate(variables):\n",
    "    for fi, func in enumerate(functions):\n",
    "        # print(f'var = {var}, func = {func}', var not in func)\n",
    "        if var not in func:\n",
    "            w23_flags[vi][fi] = False\n",
    "\n",
    "w23_flags = tf.constant(w23_flags, dtype=tf.bool)\n",
    "\n",
    "# Initialize the weights (w23) with zeros\n",
    "w23 = tf.constant(tf.zeros(num_hidden, dtype=tf_precision))\n",
    "# Set the weights to 1 where func_flags is True\n",
    "w23 = tf.where(w23_flags, tf.ones_like(w23), w23)\n",
    "w23 = tf.transpose(w23)\n",
    "\n",
    "## Weights to Layer 4 - determined by the coefficients of the functions\n",
    "# Initialize the weights (w34) with zeros\n",
    "w34_np = np.zeros([num_functions, num_output], dtype=np_precision)\n",
    "# Assign scalar coefficients to the first column of w34_np\n",
    "row = 0\n",
    "for sci, scalar_coeffs in enumerate(scalar_coefficients):\n",
    "    for scj, scl_coeff in enumerate(scalar_coeffs):\n",
    "        w34_np[row, sci] = scl_coeff\n",
    "        row += 1\n",
    "# Tranform to tensor\n",
    "w34 = tf.constant(w34_np, dtype=tf_precision)\n",
    "\n",
    "if load_initial_estimate is None:\n",
    "    w12 = tf.Variable(tf.random.normal([num_input, num_hidden[0]]), \n",
    "                      dtype=tf_precision, \n",
    "                      constraint=NonNeg())\n",
    "    \n",
    "    initial_solution = w12.numpy()[0].tolist()\n",
    "    \n",
    "elif isinstance(load_initial_estimate, str):\n",
    "    print('Loading initial estimate...')\n",
    "    # Load json file with initial estimate (best from the previous run)\n",
    "    with open(os.path.join(problem_name, f'{load_initial_estimate}.json'), 'r') as file:\n",
    "        data = json.load(file)\n",
    "    init_estimate = data['best_solution']\n",
    "    initial_solution = [float(x) for x in init_estimate.values()]\n",
    "    w12 = tf.Variable(tf.constant([initial_solution], dtype=tf_precision), constraint=NonNeg())\n",
    "\n",
    "elif load_initial_estimate == True:\n",
    "    init_estimate = load_most_recent_estimate(problem_name)\n",
    "    initial_solution = [float(x) for x in init_estimate.values()]\n",
    "    w12 = tf.Variable(tf.constant([initial_solution], dtype=tf_precision), constraint=NonNeg())\n",
    "    \n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    ## Variables - weights to Layer 1\n",
    "    # Create the variable with the non-negativity constraint\n",
    "    'w12': w12,\n",
    "    # Whether the functions in F1 and F2 contain the variables x1 and x2\n",
    "    'w23': w23,\n",
    "    # # The coefficients of the functions in F1 and F2\n",
    "    'w34': w34\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'b12': tf.constant(tf.zeros([num_hidden[0]], dtype=tf_precision)),\n",
    "    'b23': tf.constant(tf.zeros([num_hidden[1]], dtype=tf_precision)),\n",
    "    'out': tf.constant([bias_coefficients], dtype=tf_precision),\n",
    "}\n",
    "\n",
    "# Stochastic gradient descent optimizer.\n",
    "optimizer = Adam(learning_rate=learning_rate, name='custom_optimizer_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(1, 10) dtype=float64, numpy=\n",
       "array([[5.00000017e-01, 2.46398870e-08, 4.99999964e-01, 3.64818036e-08,\n",
       "        3.19337196e-07, 9.99999505e-01, 1.66666715e-01, 3.33333288e-01,\n",
       "        3.33333246e-01, 1.66666762e-01]])>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights['w12']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      0 => loss: 1.6882528101164943e-15 | best loss: 1.6882528101164943e-15 (0)\n",
      "epoch    500 => loss: 5.7673191535376276e-17 | best loss: 4.3841518673133084e-17 (363)\n",
      "epoch   1000 => loss: 9.4040595952352286e-14 | best loss: 3.6554897158223421e-17 (948)\n",
      "epoch   1500 => loss: 1.4377210317776170e-13 | best loss: 2.6449987964127928e-17 (1459)\n",
      "epoch   2000 => loss: 9.4580934370895463e-17 | best loss: 1.7974035556307145e-17 (1777)\n",
      "epoch   2500 => loss: 2.6552143548175160e-15 | best loss: 1.2756454768679111e-17 (2002)\n",
      "epoch   3000 => loss: 1.0109628541630270e-17 | best loss: 1.0109628541630270e-17 (3000)\n",
      "epoch   3500 => loss: 8.6772750393882910e-18 | best loss: 8.6772750393882910e-18 (3500)\n",
      "epoch   4000 => loss: 7.2034617527009997e-18 | best loss: 7.2034617527009997e-18 (4000)\n",
      "epoch   4500 => loss: 5.7613096491868656e-18 | best loss: 5.7613096491868656e-18 (4500)\n",
      "epoch   5000 => loss: 4.4241601425007948e-18 | best loss: 4.4241601425007948e-18 (5000)\n"
     ]
    }
   ],
   "source": [
    "best_loss = np.inf  # Initialize with infinity or an appropriate initial value\n",
    "\n",
    "# Initialize variables to store the best solution\n",
    "best_solution = None\n",
    "best_epoch = None\n",
    "# # Define the number of epochs after which to save the best weights\n",
    "# save_interval = training_steps // 100    # Every 1% of the training steps \n",
    "\n",
    "lambda_reg = float(config_data['lambda_regularization'])\n",
    "\n",
    "for i in range(training_steps):\n",
    "    \n",
    "    current_loss = train_step(weights, biases, optimizer, lambda_reg=lambda_reg)\n",
    "    \n",
    "    # Check if the current loss is better than the best loss\n",
    "    if current_loss < best_loss:\n",
    "        best_loss = current_loss\n",
    "        best_epoch = i\n",
    "        best_solution = weights['w12'].numpy()[0].copy()\n",
    "       \n",
    "    if i % display_step == 0:\n",
    "        print(f\"epoch {i:6d} => loss: {current_loss:.16e} | best loss: {best_loss:.16e} ({best_epoch})\")\n",
    "        \n",
    "    if current_loss <= 1e-20:\n",
    "        print(f\"epoch {i:6d} => loss: {current_loss:.16e} | best loss: {best_loss:.16e} ({best_epoch})\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save best solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_best_solution is not None:\n",
    "    \n",
    "    best_solution_dict = dict()\n",
    "    initial_solution_dict = dict()\n",
    "    for vi, var in enumerate(variables):\n",
    "        initial_solution_dict[var] = f'{initial_solution[vi]:.16f}'\n",
    "        best_solution_dict[var] = f'{best_solution[vi]:.16f}'\n",
    "        \n",
    "    save_solution_dict = {\n",
    "        'initial_estimate': initial_solution_dict,\n",
    "        'best_solution': best_solution_dict,\n",
    "        'best_epoch': best_epoch,\n",
    "    }\n",
    "        \n",
    "    now = datetime.now()\n",
    "    dt_string = now.strftime(\"%y%m%d %H%M%S\")\n",
    "    save_file_path = os.path.join(problem_name, f'best_estimate_{dt_string.split()[0]}_{dt_string.split()[1]}.json')\n",
    "    \n",
    "    # Save the configuration data to the JSON file\n",
    "    with open(save_file_path, 'w') as config_file:\n",
    "        json.dump(save_solution_dict, config_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST SOLUTION\n",
      "a_21 = 0.4999999987634647\n",
      "a_31 = 0.0000000165469802\n",
      "a_32 = 0.4999999829570089\n",
      "a_41 = 0.0000000312536184\n",
      "a_42 = 0.0000000515630700\n",
      "a_43 = 0.9999998729895415\n",
      "b_1 = 0.1666666807711204\n",
      "b_2 = 0.3333333081783182\n",
      "b_3 = 0.3333333171689756\n",
      "b_4 = 0.1666666938983497\n",
      "\n",
      "RESIDUALS\n",
      "+---------------------------------------------------------------------------------------------------+---------------------+\n",
      "| Equation                                                                                          |   Function residual |\n",
      "+===================================================================================================+=====================+\n",
      "| b_1 + b_2 + b_3 + b_4 - 1 =                                                                       |          1.6764e-11 |\n",
      "+---------------------------------------------------------------------------------------------------+---------------------+\n",
      "| 2*a_21*b_2 + 2*b_3*(a_31 + a_32) + 2*b_4*(a_41 + a_42 + a_43) - 1 =                               |          2.7423e-09 |\n",
      "+---------------------------------------------------------------------------------------------------+---------------------+\n",
      "| 6*a_21*a_32*b_3 + 6*b_4*(a_21*a_42 + a_43*(a_31 + a_32)) - 1 =                                    |          9.4928e-10 |\n",
      "+---------------------------------------------------------------------------------------------------+---------------------+\n",
      "| 3*a_21^2*b_2 + 3*b_3*(a_31 + a_32)^2 + 3*b_4*(a_41 + a_42 + a_43)^2 - 1 =                         |          4.7792e-09 |\n",
      "+---------------------------------------------------------------------------------------------------+---------------------+\n",
      "| 24*a_21*a_32*a_43*b_4 - 1 =                                                                       |          1.7944e-10 |\n",
      "+---------------------------------------------------------------------------------------------------+---------------------+\n",
      "| 12*a_21^2*a_32*b_3 + 12*b_4*(a_21^2*a_42 + a_43*(a_31 + a_32)^2) - 1 =                            |          7.8327e-10 |\n",
      "+---------------------------------------------------------------------------------------------------+---------------------+\n",
      "| 8*a_21*a_32*b_3*(a_31 + a_32) + 8*b_4*(a_21*a_42 + a_43*(a_31 + a_32))*(a_41 + a_42 + a_43) - 1 = |          1.7678e-10 |\n",
      "+---------------------------------------------------------------------------------------------------+---------------------+\n",
      "| 4*a_21^3*b_2 + 4*b_3*(a_31 + a_32)^3 + 4*b_4*(a_41 + a_42 + a_43)^3 - 1 =                         |          1.8531e-09 |\n",
      "+---------------------------------------------------------------------------------------------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "func_res_model, solution  = multilayer_perceptron(weights, biases)\n",
    "solution = list(solution.numpy()[0])\n",
    "best_solution = list(best_solution)\n",
    "\n",
    "print('BEST SOLUTION')\n",
    "for i, var in enumerate(variables):\n",
    "    print(f'{var} = {best_solution[i]:.16f}')\n",
    "    \n",
    "print()\n",
    "print('RESIDUALS')\n",
    "# headers = ['Equation', 'Model residual', 'Function residual']\n",
    "headers = ['Equation', 'Function residual']\n",
    "table_data = []\n",
    "\n",
    "for f, func in enumerate(equations):\n",
    "    eq = equations_sym[f]\n",
    "    equation = lambdify(variables_sym, eq)\n",
    "    func_res_eq = abs(equation(*best_solution))\n",
    "    # table_data.append([f'{func} = ', f'{abs(func_res_model[0, f]):.4e}', f'{func_res_eq:.4e}'])\n",
    "    table_data.append([f'{func} = ', f'{func_res_eq:.4e}'])\n",
    "\n",
    "print(tabulate(table_data, headers=headers, tablefmt='grid'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-nn-systems",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
